{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q4nLlyzHvntZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "my4Ri_NSwzX7"
   },
   "outputs": [],
   "source": [
    "directors = []\n",
    "actors = []\n",
    "mpaaRatings = []\n",
    "X = [] # This holds the movie data that the model will use to train.\n",
    "y = [] # This holds whether the movies won an oscar or not that the model will use to train.\n",
    "\n",
    "dummyData = pd.read_csv(\"../Data/oscars.csv\", encoding = \"ISO-8859-1\")\n",
    "n = len(dummyData.index)\n",
    "\n",
    "for i in range(0, n):\n",
    "    movie = list(dummyData.iloc[i])\n",
    "    director = movie[7]\n",
    "    actor1 = movie[11]\n",
    "    actor2 = movie[15]\n",
    "    actor3 = movie[19]\n",
    "    mpaaRating = movie[23]\n",
    "    \n",
    "    if not(director in directors):\n",
    "        directors.append(director)\n",
    "    movie[7] = directors.index(director) # replace director to its unique numerical value\n",
    "    movie[8] = int(movie[8])\n",
    "    \n",
    "    if not(actor1 in actors):\n",
    "        actors.append(actor1)\n",
    "    movie[11] = actors.index(actor1)\n",
    "    movie[12] = int(movie[12])\n",
    "    \n",
    "    if not(actor2 in actors):\n",
    "        actors.append(actor2)\n",
    "    movie[15] = actors.index(actor2)\n",
    "    movie[16] = int(movie[16])\n",
    "    \n",
    "    if not(actor3 in actors):\n",
    "        actors.append(actor3)\n",
    "    movie[19] = actors.index(actor3)\n",
    "    movie[20] = int(movie[20])\n",
    "    \n",
    "    if not(mpaaRating in mpaaRatings):\n",
    "        mpaaRatings.append(mpaaRating)\n",
    "    movie[23] = mpaaRatings.index(mpaaRating) # replace mpaa rating to its unique numerical value\n",
    "    \n",
    "    X.append(movie[3:])\n",
    "    y.append(int(movie[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g7i03TOc0evJ"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "c_values = [1, 10, 100]\n",
    "penalty_type = ['l1', 'l2']\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in range(0,2):\n",
    "        data.append([\"C\", \"penalty\", \"Round 1\", \"Round 2\", \"Round 3\", \"Round 4\", \"Round 5\", \"Round 6\", \"Round 7\", \"Round 8\", \"Round 9\", \"Round 10\", \"Avg F1 Score\", \"Avg Accuracy\"])\n",
    "        data_row = []\n",
    "        data_row.append(c_values[i])\n",
    "        data_row.append(penalty_type[j])\n",
    "        f1_scores = []\n",
    "        accuracy = []\n",
    "        for k in range(0, 10):\n",
    "            # train_test_split takes the datasets, shuffles the datasets, and splits it into training and testing sets.\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, stratify = y)\n",
    "\n",
    "            sc = StandardScaler()\n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_test = sc.transform(X_test)\n",
    "            classifier = LogisticRegression(random_state = 0, C=c_values[i], penalty=penalty_type[j])\n",
    "            classifier.fit(X_train, y_train)\n",
    "            \n",
    "            predictions = classifier.predict(X_test) # This predict function produces yes or no Oscar predictions.\n",
    "            proba_predictions = classifier.predict_proba(X_test)[:,1] # This predict_proba function produces the probability of the movies winning an oscar.\n",
    "            \n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "            f1_score = 2 * tp / (2 * tp + fp + fn)\n",
    "            f1_scores.append(f1_score)\n",
    "            data_row.append(round(f1_score,3))\n",
    "            accuracy.append(accuracy_score(y_test,predictions))\n",
    "        \n",
    "        avg_f1 = np.mean(f1_scores)\n",
    "        avg_accuracy = np.mean(accuracy)\n",
    "        data_row.append(round(avg_f1,3))  \n",
    "        data_row.append(round(avg_accuracy,3))\n",
    "        data.append(data_row)\n",
    "with open(\"logistic_regression_data.csv\",\"w+\") as csv_file:\n",
    "    csvWriter = csv.writer(csv_file,delimiter=',')\n",
    "    csvWriter.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-1CUZPu0qOv",
    "outputId": "5f0c5812-78af-4388-cbb8-addaf19079fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIXbd9-m0vOr",
    "outputId": "e8a8168e-cb89-4277-abcb-19a3d06f249c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\tActual\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "pretty_list = \"\\n\".join(\"{}\\t\\t{}\".format(x, y) for x, y in zip(predictions, y_test))\n",
    "print(\"Predictions\\tActual\")\n",
    "print(pretty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-awKR3cs2COM",
    "outputId": "8f96b268-53b6-4ed3-9e51-90766559f4f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of 1 \tActual\n",
      "0.05\t0\n",
      "0.19\t0\n",
      "0.11\t0\n",
      "0.66\t1\n",
      "0.57\t0\n",
      "0.69\t0\n",
      "0.14\t0\n",
      "0.18\t0\n",
      "0.53\t1\n",
      "0.00\t0\n",
      "0.59\t1\n",
      "0.03\t0\n",
      "0.17\t0\n",
      "0.18\t0\n",
      "0.01\t0\n",
      "0.13\t0\n",
      "0.65\t0\n",
      "0.40\t0\n",
      "0.09\t0\n",
      "0.10\t0\n",
      "0.09\t0\n",
      "0.11\t0\n",
      "0.18\t0\n",
      "0.15\t1\n",
      "0.04\t0\n"
     ]
    }
   ],
   "source": [
    "predictions_percent = classifier.predict_proba(X_test)[:,1]\n",
    "pretty_list = \"\\n\".join(\"{:.2f}\\t{}\".format(x, y) for x, y in zip(predictions_percent, y_test))\n",
    "print(\"% of 1 \\tActual\")\n",
    "print(pretty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OQaa0eJ1i6Z",
    "outputId": "de9f5869-a4e3-417a-e8a2-31fafbd37d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  3]\n",
      " [ 1  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiXcNTAR1lrT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LogisticRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
